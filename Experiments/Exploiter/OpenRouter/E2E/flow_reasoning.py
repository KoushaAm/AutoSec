import os
import re
import json
from dotenv import load_dotenv
from openai import OpenAI
from utils.models import *
from E2E.prompts import *

# helpers 
JAVA_FILE_EXTS = ('.java')
PROJECT_ROOT = "../project_cmd_2"
SARIF_SUMMARY_PATH = "E2E/assets/data_preprocessed.json"




def grep_matches(root: str, pattern: str, max_hits: int = 200):
    """Return list of tuples: (path, line_number, line_text). Simple substring or regex search."""
    matches = []
    try:
        regex = re.compile(pattern)
    except re.error:
        regex = None
    for dirpath, _, filenames in os.walk(root):
        for fname in filenames:
            if not fname.lower().endswith(JAVA_FILE_EXTS):
                continue
            path = os.path.join(dirpath, fname)
            try:
                with open(path, 'r', encoding='utf-8', errors='ignore') as fh:
                    for i, raw_line in enumerate(fh, start=1):
                        line = raw_line.rstrip('\n')
                        hit = False
                        if regex:
                            if regex.search(line): # perform the serach
                                hit = True
                        else:
                            if pattern in line:
                                hit = True
                        if hit:
                            matches.append((path, i, line.strip()))
                            if len(matches) >= max_hits:
                                return matches
            except Exception:
                continue
    return matches

def read_snippet(path: str, center_line: int, context: int = 6):
    """Return snippet around center_line. 1-based line numbers; include context lines each side."""
    try:
        with open(path, 'r', encoding='utf-8', errors='ignore') as fh:
            lines = fh.read().splitlines()
    except Exception:
        return ""
    lo = max(0, center_line - context - 1)
    hi = min(len(lines), center_line + context)
    snippet = "\n".join(lines[lo:hi])
    # add small header with line numbers for clarity
    numbered = []
    for idx, ln in enumerate(lines[lo:hi], start=lo+1):
        numbered.append(f"{idx:4d}: {ln}")
    return "\n".join(numbered)

# Build evidence for LLM
def collect_evidence(project_root: str, sarif_summary: str, max_items: int = 120):
    """
    collect evidence snippets from the Java project that may help the LLM reason about data flows.
    Return a list of dicts with keys: file, path, line, line_text, snippet
    """

    # this patterns focus mainly ond CMD or code injections
    # we can broaden this pattern list later with information on source and sinks given by IRIS
    patterns = [
        r"Runtime\.getRuntime\(\)\.exec",
        r"\.exec\(",
        r"ProcessBuilder\(",
        r"ProcessBuilder\.start",
        r"Runtime\.exec",
        r"ELProcessor\.eval",
        r"ExpressionFactory",
        r"@Cron",
        r"@Cronan",
        r"Template",
        r"eval\(",
    ]

    evidence = []
    seen = set()

    # search for pattern hits
    for pat in patterns:
        print(pat)
        hits = grep_matches(project_root, pat, max_hits=max_items)
        for (path, ln, line_text) in hits:
            key = (path, ln, line_text)
            if key in seen:
                continue
            seen.add(key)
            snippet = read_snippet(path, ln, context=6)
            evidence.append({"file": os.path.relpath(path, project_root), "path": path, "line": ln, "line_text": line_text, "snippet": snippet})
            if len(evidence) >= max_items:
                break
        if len(evidence) >= max_items:
            break

    # if none found, look for filename mentions in sarif_summary
    if not evidence:
        fname_matches = re.findall(r'\b([A-Za-z0-9_\-]+\.java)\b', sarif_summary)
        for fname in fname_matches:
            hits = grep_matches(project_root, re.escape(fname), max_hits=50)
            for path, ln, line_text in hits:
                key = (path, ln, line_text)
                if key in seen:
                    continue
                seen.add(key)
                snippet = read_snippet(path, ln, context=6)
                evidence.append({"file": os.path.relpath(path, project_root), "path": path, "line": ln, "line_text": line_text, "snippet": snippet})
                if len(evidence) >= max_items:
                    break
            if len(evidence) >= max_items:
                break

    # final fallback: add first few java files' headers
    if not evidence:
        for dirpath, _, filenames in os.walk(project_root):
            for fname in filenames:
                if fname.lower().endswith('.java'):
                    path = os.path.join(dirpath, fname)
                    snippet = read_snippet(path, 1, context=3)
                    evidence.append({"file": os.path.relpath(path, project_root), "path": path, "line": 1, "line_text": "(file start)", "snippet": snippet})
                    if len(evidence) >= max_items:
                        break
            if len(evidence) >= max_items:
                break

    return evidence



# prompt assembly and LLM call (used by prompt_gen.py main)
def request_flow(client, model, base_prompt: str, project_root: str, sarif_summary: str):
    """
    Append evidence section and the <FLOW> instruction to the base prompt, call LLM,
    and extract/return parsed JSON flow.
    """

    # obtains key lines that may qualify as source points
    evidence = collect_evidence(project_root, sarif_summary, max_items=100)
    evidence_text = ""
    for e in evidence[:80]:
        evidence_text += f"FILE: {e['file']}\nLINE: {e['line']}\nCODE: {e['line_text']}\nSNIPPET:\n{e['snippet']}\n---\n"
    
    flow_instructions = (
        "\n\nCould you generate a sequence of program points to reach the vulnerable point (sink), "
        "starting from an external input (source)? This corresponds to a vulnerable “flow” through the program.\n"
        "The flow should take the form of a JSON array; each element has the format:\n"
        '{ "role": "Source|Intermediate|Sink",\n'
        '  "code": "1-3 lines of source code",\n'
        '  "variable": "variable name or null",\n'
        '  "file": "file path (relative to project root)",\n'
        '  "start_line": integer (if available),\n'
        '  "remarks": "optional comments"\n'
        '}\n\n'
        "Use the evidence section below to guide your reasoning. When you are finished, place the JSON array "
        "between the tags <FLOW> and </FLOW> and output nothing else.\n\n"
        "EVIDENCE (top matches):\n" + evidence_text + "\n\n"
        "SARIF SUMMARY:\n" + sarif_summary + "\n\n"
        "<FLOW>\n"
    )

    full_prompt = base_prompt + flow_instructions

    # send to LLM using your generate(client, model, prompt)
    raw = generate(client, model, full_prompt)


    """
    everything below is for parsing LLM output into clean JSON
    """
    # extract content between <FLOW> and </FLOW>
    txt = raw.strip()
    # removing markdown fences if present
    txt = re.sub(r"^```(?:json|text|)?\s*", "", txt)
    txt = re.sub(r"\s*```$", "", txt)

    # find tags
    m = re.search(r"<FLOW>(.*?)</FLOW>", txt, flags=re.DOTALL | re.IGNORECASE)
    if not m:
        # fallback: try to find first JSON array in output
        m2 = re.search(r"(\[.*\])", txt, flags=re.DOTALL)
        if m2:
            json_text = m2.group(1)
        else:
            # if nothing parseable, return raw for inspection
            json_text = txt
    else:
        json_text = m.group(1).strip()

    # try to clean possible leading/trailing code fences
    json_text = json_text.strip()
    json_text = re.sub(r"^```(?:json)?\s*", "", json_text)
    json_text = re.sub(r"\s*```$", "", json_text)

    # parse json
    try:
        parsed = json.loads(json_text)
    except Exception:
        # if failed try via regex for JSON array
        m3 = re.search(r"(\[.*\])", json_text, flags=re.DOTALL)
        if m3:
            try:
                parsed = json.loads(m3.group(1))
            except Exception:
                parsed = {"raw": json_text}
        else:
            parsed = {"raw": json_text}

    return {"raw_response": raw, "flow": parsed, "evidence_count": len(evidence)}





if __name__ == "__main__":
    # model initialization
    client, model = initialize()

    base_prompt = BASE_PROMPT

    with open(SARIF_SUMMARY_PATH, "r", encoding="utf-8") as f:
        sarif_summary = f.read()

    result = request_flow(client, model, base_prompt, PROJECT_ROOT, sarif_summary)

    print("Raw LLM Response:")
    print(result["raw_response"])
    print("\nParsed Flow:")
    print(json.dumps(result["flow"], indent=2))

    with open("E2E/assets/flow.json", "w", encoding="utf-8") as f:
        json.dump(result, f, indent=2)
