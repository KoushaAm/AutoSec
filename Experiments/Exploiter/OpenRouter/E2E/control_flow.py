import os
import re
import json
from utils.models import *
from openai import OpenAI
from dotenv import load_dotenv
from E2E.prompts import *
import time

BRANCH_PATTERNS = [
    r"\bif\s*\(",
    r"\belse\s+if\s*\(",
    r"\bswitch\s*\(",
    r"\btry\b",
    r"\bcatch\s*\(",
]

def read_snippet(path, start_line, context=12):
    """Return code snippet around start_line with some context."""
    try:
        with open(path, "r", encoding="utf-8", errors="ignore") as fh:
            lines = fh.read().splitlines()
    except Exception:
        return ""
    lo, hi = max(0, start_line - context - 1), min(len(lines), start_line + context)
    # numbered snippet
    numbered = [f"{i+1:4d}: {ln}" for i, ln in enumerate(lines[lo:hi], start=lo)]
    return "\n".join(numbered)


def collect_branch_evidence(project_root, flow_json, max_items=80):
    """Extract branch conditions around program points in flow output."""
    evidence = []
    seen = set()

    for node in flow_json:
        file = node.get("file")
        start_line = node.get("start_line", 1)
        if not file:
            continue
        path = os.path.join(project_root, file)
        if not os.path.exists(path):
            continue
        snippet = read_snippet(path, start_line, context=20)
        for pat in BRANCH_PATTERNS:
            for m in re.finditer(pat, snippet):
                context_lines = snippet.split("\n")
                branch_snippet = "\n".join(context_lines)
                key = (file, pat)
                if key in seen:
                    continue
                seen.add(key)
                evidence.append({
                    "file": file,
                    "pattern": pat,
                    "snippet": branch_snippet
                })
                if len(evidence) >= max_items:
                    return evidence
    return evidence


def request_branch_reasoning(client, model, base_prompt, project_root, flow_json, sarif_summary):
    """Prompt LLM to extract branch conditions + input constraints."""
    evidence = collect_branch_evidence(project_root, flow_json)
    evidence_text = ""
    for e in evidence:
        evidence_text += (
            f"FILE: {e['file']}\nPATTERN: {e['pattern']}\nSNIPPET:\n{e['snippet']}\n---\n"
        )

    prompt = (
        base_prompt
        + "\n\nYou are a Control Flow Reasoning Agent.\n"
        "Given the data flow path (from <SOURCE> to <SINK>) and the evidence below, "
        "extract all branch conditions (if/else, switch, try/catch) that an input "
        "might encounter along the control flow path leading to the sink.\n\n"
        "For each branch condition, produce an object of the form:\n"
        "{ \"code\": \"if (x == null)\", \"type\": \"If-Else\", \"file\": \"CronValidator.java\", "
        "\"outcome\": \"False - the value should not be null\" }\n\n"
        "After listing all branch conditions as a JSON array between <BRANCHES>...</BRANCHES>, "
        "reflect on them and infer a concise list of input conditions that must hold "
        "for the execution to reach the sink. Format this as a second JSON array between <INPUT_CONDITIONS>...</INPUT_CONDITIONS>.\n\n"
        f"SARIF SUMMARY:\n{sarif_summary}\n\n"
        "DATA FLOW (previous step):\n" + json.dumps(flow_json, indent=2) + "\n\n"
        "BRANCH EVIDENCE:\n" + evidence_text + "\n"
        "Output only the JSON between <BRANCHES> and <INPUT_CONDITIONS> tags.\n"
    )

    response = generate(client, model, prompt)

    # extract branch and input sections
    raw = response.strip()
    branches_match = re.search(r"<BRANCHES>(.*?)</BRANCHES>", raw, re.DOTALL)
    input_match = re.search(r"<INPUT_CONDITIONS>(.*?)</INPUT_CONDITIONS>", raw, re.DOTALL)

    branches = []
    input_conditions = []
    try:
        if branches_match:
            branches = json.loads(branches_match.group(1))
        if input_match:
            input_conditions = json.loads(input_match.group(1))
    except Exception:
        pass

    return {
        "raw_response": response,
        "branches": branches,
        "input_conditions": input_conditions,
        "evidence_count": len(evidence),
    }


if __name__ == "__main__":
    load_dotenv()
    client, model = initialize()

    # PROJECT_ROOT = "../jenkinsci__workflow-cps-global-lib-plugin_CVE-2022-25174_544.vff04fa68714d"
    PROJECT_ROOT = "../jenkinsci__workflow-cps-global-lib-plugin_CVE-2022-25174_544.vff04fa68714d"
    # sarif_summary = open("E2E/assets/data_preprocessed_cps.json").read()
    sarif_summary = open("out/preprocessed_results.json").read()
    flow_json = json.load(open("E2E/assets/data_flow_061125_111718.json"))["flow"]

    result = request_branch_reasoning(client, model, BASE_PROMPT, PROJECT_ROOT, flow_json, sarif_summary)
    time_postfix = time.strftime("%d%m%y_%H%M%S")

    with open(f"E2E/assets/control_flow{time_postfix}.json", "w") as f:
        json.dump(result, f, indent=2)
    print("branch reasoning complete. Output saved.")