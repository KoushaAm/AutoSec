import os
import re
import json
from dotenv import load_dotenv
from openai import OpenAI
from utils.models import *
from E2E.prompts import *

# helpers 
JAVA_FILE_EXTS = ('.java') # file extensions to consider
PROJECT_ROOT = "../jenkinsci__perfecto-plugin_CVE-2020-2261_1.17"
SARIF_SUMMARY_PATH = "E2E/assets/data_preprocessed_perfecto.json"



SINK_PATTERNS = [
    r"Runtime\.getRuntime\(\)\.exec",
    r"ProcessBuilder",
    r"\.exec\(",
    r"ELProcessor\.eval",
    r"ExpressionFactory",
    r"eval\(",
]

SOURCE_PATTERNS = [
    r"Scanner\s*\(",
    r"BufferedReader\s*\(",
    r"HttpServletRequest",
    r"request\.getParameter",
    r"System\.in",
    r"Files\.readString", 
    r"InputStreamReader",
    r"@RequestParam",
    r"@RequestBody",
]



def grep_matches(root, patterns, max_hits=200):
    matches = []
    for dirpath, _, filenames in os.walk(root):
        for fname in filenames:
            if not fname.endswith(JAVA_FILE_EXTS):
                continue
            path = os.path.join(dirpath, fname)
            try:
                with open(path, "r", encoding="utf-8", errors="ignore") as f:
                    for i, line in enumerate(f, start=1):
                        for pat in patterns:
                            if re.search(pat, line):
                                matches.append((path, i, line.strip()))
                                if len(matches) >= max_hits:
                                    return matches
            except Exception:
                continue
    return matches


def summarize_file_structure(project_root: str): 
    """Return a brief summary of the Java project file structure."""
    summary = []
    for dirpath, dirnames, filenames in os.walk(project_root):
        level = dirpath.replace(project_root, '').count(os.sep)
        indent = "  " * level
        subdir = os.path.basename(dirpath)
        summary.append(f"{indent}{subdir}/")
        for fname in filenames:
            if fname.endswith(JAVA_FILE_EXTS):
                summary.append(f"{indent}  -  {fname}")
    return "\n".join(summary)


def read_snippet(path: str, center_line: int, context: int = 6):
    """Return snippet around center_line. 1-based line numbers; include context lines each side."""
    try:
        with open(path, 'r', encoding='utf-8', errors='ignore') as fh:
            lines = fh.read().splitlines()
    except Exception:
        return ""
    lo = max(0, center_line - context - 1)
    hi = min(len(lines), center_line + context)
    snippet = "\n".join(lines[lo:hi])
    # add small header with line numbers for clarity
    numbered = []
    for idx, ln in enumerate(lines[lo:hi], start=lo+1):
        numbered.append(f"{idx:4d}: {ln}")
    return "\n".join(numbered)


# build evidence for LLM
def collect_dynamic_evidence(project_root, sarif_summary, max_items=120):
    evidence = []
    seen = set()

    # find all sinks first: based on SINK_PATTERNS
    for (path, ln, line) in grep_matches(project_root, SINK_PATTERNS, max_hits=max_items):
        key = (path, ln)
        if key in seen:
            continue
        seen.add(key)
        snippet = read_snippet(path, ln, context=8)
        evidence.append({"role": "Sink", "path": path, "line": ln, "code": line, "snippet": snippet})

    # find all sources next: based on SOURCE_PATTERNS
    for (path, ln, line) in grep_matches(project_root, SOURCE_PATTERNS, max_hits=max_items):
        key = (path, ln)
        if key in seen:
            continue
        seen.add(key)
        snippet = read_snippet(path, ln, context=8)
        evidence.append({"role": "Source", "path": path, "line": ln, "code": line, "snippet": snippet})

    # imports and high-level summaries
    if not evidence:
        for dirpath, _, files in os.walk(project_root):
            for fname in files:
                if fname.endswith(".java"):
                    p = os.path.join(dirpath, fname)
                    with open(p, "r", encoding="utf-8", errors="ignore") as f:
                        lines = f.readlines()[:20]
                        evidence.append({"role": "File", "path": p, "snippet": "".join(lines)})
                    if len(evidence) >= max_items:
                        break
            if len(evidence) >= max_items:
                break

    return evidence


def flow_text_to_json(raw: str):
    """
    Parse LLM response to extract JSON flow between <FLOW> and </FLOW> tags.
    """
    # Extract content between <FLOW> and </FLOW>, robust to code fences and extra text
    txt = raw.strip()
    txt = re.sub(r"^```(?:json|text)?\s*", "", txt, flags=re.IGNORECASE)
    txt = re.sub(r"\s*```$", "", txt, flags=re.IGNORECASE)

    m = re.search(r"<FLOW>(.*?)</FLOW>", txt, flags=re.DOTALL | re.IGNORECASE)
    if m:
        json_text = m.group(1).strip()
    else:
        # fallback: try to find the first JSON array in the response
        m2 = re.search(r"(\[.*\])", txt, flags=re.DOTALL)
        if m2:
            json_text = m2.group(1)
        else:
            json_text = txt  # return raw for inspection if parsing fails

    # clean possible code fences around json_text
    json_text = re.sub(r"^```(?:json)?\s*", "", json_text, flags=re.IGNORECASE).strip()
    json_text = re.sub(r"\s*```$", "", json_text, flags=re.IGNORECASE).strip()

    # Try to parse the JSON; on failure return raw text in flow.raw
    try:
        parsed = json.loads(json_text)
    except Exception:
        # attempt to salvage a JSON array with a relaxed regex
        m3 = re.search(r"(\[.*\])", json_text, flags=re.DOTALL)
        if m3:
            try:
                parsed = json.loads(m3.group(1))
            except Exception:
                parsed = {"raw": json_text}
        else:
            parsed = {"raw": json_text}
    
    return parsed

# prompt assembly and LLM call (used by prompt_gen.py main)
def request_flow(client, model, base_prompt: str, project_root: str, sarif_summary: str):
    """
    Append evidence section and the <FLOW> instruction to the base prompt, call LLM,
    and extract/return parsed JSON flow.

    This version uses collect_dynamic_evidence(...) to find sinks and sources across
    complex project layouts, but formats the evidence exactly like the original function
    so the flow prompt and returned structure remain unchanged.
    """

    # use the improved evidence collector (must be implemented elsewhere)
    # collect_dynamic_evidence returns items like:
    #   {"role":"Sink"|"Source"|"File", "path": "/abs/path/...", "line": ln, "code": "line text", "snippet": "..." }
    dynamic = collect_dynamic_evidence(project_root, sarif_summary, max_items=200)

    # convert dynamic evidence to the old evidence format expected by the prompt:
    # { "file", "path", "line", "line_text", "snippet" }
    evidence = []
    seen = set()
    for e in dynamic:
        # normalize path relative to project root
        rel = os.path.relpath(e.get("path", ""), project_root) if e.get("path") else e.get("file", "UNKNOWN")
        ln = e.get("line", 1)
        line_text = e.get("code", e.get("line_text", "")).strip()
        snippet = e.get("snippet", "")
        key = (rel, ln, line_text)
        if key in seen:
            continue
        seen.add(key)
        evidence.append({"file": rel, "path": e.get("path", ""), "line": ln, "line_text": line_text, "snippet": snippet})
        if len(evidence) >= 100:
            break


    # build evidence_text in the exact same format you used before
    evidence_text = ""
    for e in evidence[:80]:
        evidence_text += f"FILE: {e['file']}\nLINE: {e['line']}\nCODE: {e['line_text']}\nSNIPPET:\n{e['snippet']}\n---\n"

    # keep the exact same flow instructions / schema you used earlier
    flow_instructions = (
        "\n\nCould you generate a sequence of program points to reach the vulnerable point (sink), "
        "starting from an external input (source)? This corresponds to a vulnerable “flow” through the program.\n"
        "The flow should take the form of a JSON array; each element has the format:\n"
        '{ "role": "Source|Intermediate|Sink",\n'
        '  "code": "1-3 lines of source code",\n'
        '  "variable": "variable name or null",\n'
        '  "file": "file path (relative to project root)",\n'
        '  "start_line": integer (if available),\n'
        '  "remarks": "optional comments"\n'
        '}\n\n'
        "Use the evidence section below to guide your reasoning. When you are finished, place the JSON array "
        "between the tags <FLOW> and </FLOW> and output nothing else.\n\n"
        "EVIDENCE (top matches):\n" + evidence_text + "\n\n"
        "SARIF SUMMARY:\n" + sarif_summary + "\n\n"
        "<FLOW>\n"
    )

    full_prompt = base_prompt + flow_instructions

    # send to LLM (your existing generate / call function)
    raw = generate(client, model, full_prompt)

    parsed = flow_text_to_json(raw)

    return {"raw_response": raw, "flow": parsed, "evidence_count": len(evidence)}


if __name__ == "__main__":
    # model initialization
    client, model = initialize()

    base_prompt = BASE_PROMPT

    with open(SARIF_SUMMARY_PATH, "r", encoding="utf-8") as f:
        sarif_summary = f.read()

    result = request_flow(client, model, base_prompt, PROJECT_ROOT, sarif_summary)

    print("Raw LLM Response:")
    print(result["raw_response"])
    print("\nParsed Flow:")
    print(json.dumps(result["flow"], indent=2))

    with open("E2E/assets/data_flow.json", "w", encoding="utf-8") as f:
        json.dump(result, f, indent=2)
