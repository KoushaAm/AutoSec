import requests
import os 
from dotenv import load_dotenv
from openai import OpenAI
import json
from utils.models import *
from E2E.data_flow import request_flow
import time

# directories 
# PROJECT_ROOT = "../jenkinsci__workflow-cps-global-lib-plugin_CVE-2022-25174_544.vff04fa68714d"       
PROJECT_ROOT = "../jenkinsci__perfecto-plugin_CVE-2020-2261_1.17"
# SARIF_SUMMARY_PATH = "E2E/assets/data_preprocessed_cps.json"  
SARIF_SUMMARY_PATH = "out/preprocessed_results.json"

time_postfix = time.strftime("%d%m%y_%H%M%S")
TEST_OUTPUT_PATH = f"E2E/assets/Test_perfecto_{time_postfix}.txt"



def build_tester_prompt(data_flow, control_flow, sarif_summary: str, project_root:str, sarif_summary_path = SARIF_SUMMARY_PATH) -> str: 
    
    with open(sarif_summary_path, "r", encoding="utf-8") as f:
        sarif_summary = f.read()
    
    tester_prompt = f"""
            You are the Tester agent. Produce exactly ONE output: a single Java source file containing a JUnit5 test class that *executes the actual program modules* in the given project sandbox and attempts to verify/exploit the vulnerability.

IMPORTANT SAFETY & BOUNDARY RULES:
- Your output MUST BE ONLY the Java source code (one .java file). No explanation, no markdown, no extra text.
- You MUST NOT run real external shell commands or make network calls outside the orchestrator sandbox.
- You *are allowed* to compile and run the project's code inside the orchestrator sandbox using the provided BuildAndRunDocker tool (the orchestrator will run the produced test file inside a sandbox).
- You MUST NOT attempt to exfiltrate secrets. All assertions must operate on captured strings or in-memory state.

PRIVILEGED TOOLS (ALLOWED & AVAILABLE AT RUN-TIME):
- Read(path, start_line=None, end_line=None): read file snippets from the project filesystem.
- Grep(pattern): find files and lines.
- ListDir(path)
- Write(path, content): write files in the test workspace.
- BuildAndRunDocker(dockerfile_path): build & run tests in an isolated sandbox and return logs + exit code.
Use these tools for interacting with the repo. Do NOT embed raw shell commands in the test; instead rely on BuildAndRunDocker when you need to compile/run.

GOAL:
- Use the DERIVED DATAFLOW and CONTROL FLOW to find the real target class/methods.
- Compile and run tests that call the actual Java classes and methods (in-process) to create the vulnerable execution path.
- Do not "simulate" the application by inventing fake functions; call the real code from the project.

REQUIREMENTS FOR THE GENERATED JUNIT FILE:
1) Discovery & compilation:
   - Use Read/Grep/ListDir to locate the target class and confirm method signatures before producing the test.
   - The test must be written so the orchestrator can compile it with the project's build system (Maven/Gradle). Include package declaration and full imports.
   - If the class or method is not public, prefer reflection (java.lang.reflect) to invoke it.

2) Testing in-process (real module invocation):
   - The test MUST instantiate and call the real classes/methods that construct the command or handle input (e.g., classes that build `Runtime.exec` arguments).
   - DO NOT attempt to spawn real OS shell commands. Instead capture the string(s) the program *would have passed* to Runtime.exec/ProcessBuilder:
       * Prefer using dependency injection / wrapper classes if present.
       * If the code calls `Runtime.getRuntime().exec(...)` or `new ProcessBuilder(...)`, use Mockito.spy / Mockito.mock to intercept calls and capture parameters.
       * If mocking is impossible (static/final/private), use reflection to call the method that *returns* the command string, or read fields storing the command.

3) Assertions & reporting:
   - The test must include at least 3 varied inputs (normal + attacker-like payloads).
   - For each input the test must assert whether the captured command string contains disallowed characters (allowed characters: A-Za-z0-9._-). Use regex checks.
   - The test MUST write a report to an atomic file `report.txt` in the test working directory with EXACTLY the lines (replace placeholders):
        Vulnerability Rule ID: <RULE_ID>
        CWE ID: <CWE-ID>
        InputsTested: [ "<input1>", "<input2>", "<input3>" ]
        Exploitable: YES|NO
        Rationale: <short explanation why YES or NO>
        Procedure: <short explanation of how the vulnerability was targeted>

4) Determinism & safety:
   - Tests must be deterministic, bounded in runtime, and safe to run in CI.
   - Do not perform any network calls. Do not write to system directories. Use only workspace relative paths.

5) Minimal dependencies:
   - Use only JUnit5 + Mockito (if mocking needed) or standard Java reflection APIs.
   - Include all imports in the Java file.

HOW TO USE PROJECT BUILD:
- If compilation/run requires specific build steps, assume the orchestrator will:
    * compile with the project's Maven/Gradle (the test only needs to be valid Java with correct package)
    * Run tests via BuildAndRunDocker which will call `mvn -DskipTests=false test` or equivalent.
- If you need to modify project files to make testing possible (e.g. add small wrapper), create them under a `test-harness/` package via Write(path, content). The orchestrator will include them in the build.

CONTEXT:
- Project filesystem path: {project_root}
- SARIF summary (trimmed): {sarif_summary}
- DERIVED DATAFLOW: {data_flow}
- DERIVED CONTROL FLOW: {control_flow}

OUTPUT:
- Return only the Java source file text (one .java file). The test file must be ready to compile in the repo.

End.

            """
    return tester_prompt



def main():
    client, model = initialize()

    # load SARIF summary
    if not os.path.exists(SARIF_SUMMARY_PATH):
        raise FileNotFoundError(f"SARIF summary not found at {SARIF_SUMMARY_PATH}")
    with open(SARIF_SUMMARY_PATH, "r", encoding="utf-8") as fh:
        sarif_summary = fh.read()

    # run the dataflow reasoner 
    print("* Running DataFlow Reasoner to derive flow...")
    
    # data_flow = request_flow(client, model, base_prompt:=(
    #     "You are a Static Code Reasoning Agent. Use the provided evidence to infer a Source->Sink dataflow "
    #     "for the vulnerability described in the SARIF summary. Output ONLY the JSON array between <FLOW> tags."
    # ), project_root=PROJECT_ROOT, sarif_summary=sarif_summary)

    # with open("E2E/data_flow.json", "w", encoding="utf-8") as f:
    #     json.dump(data_flow, f, indent=2)

    derived_data_flow = json.load(open("E2E/assets/data_flow_061125_111718.json"))["flow"]

    # derived_data_flow = data_flow.get("flow", [])
    print(f"* Derived flow items: {len(derived_data_flow) if isinstance(derived_data_flow, list) else 'unknown'}")

    # with open("E2E/assets/control_flow.json", "w", encoding="utf-8") as f:
    #     control_flow = json.load(f)
    control_flow = json.load(open("E2E/assets/control_flow_061125_112330.json"))["branches"]
    print(f"* Loaded control flow items: {len(control_flow) if isinstance(control_flow, list) else 'unknown'}")

    # build the tester prompt embedding the derived flow
    print("* Building Tester system prompt...")
    tester_prompt = build_tester_prompt(data_flow=derived_data_flow, control_flow=control_flow, sarif_summary=sarif_summary, project_root=PROJECT_ROOT)

    with open(TEST_OUTPUT_PATH, "w", encoding="utf-8") as f:
        f.write(tester_prompt)

    print(f"Writing tester prompt to: {TEST_OUTPUT_PATH}")

if __name__ == "__main__":
    main()